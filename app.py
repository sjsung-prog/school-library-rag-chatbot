import os
import streamlit as st

from langchain_upstage import ChatUpstage, UpstageEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough


# ğŸ”‘ Streamlit Cloudì˜ secrets.toml ì—ì„œ UPSTAGE_API_KEYë¥¼ ê°€ì ¸ì™€ì„œ í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •
if "UPSTAGE_API_KEY" in st.secrets:
    os.environ["UPSTAGE_API_KEY"] = st.secrets["UPSTAGE_API_KEY"]


@st.cache_resource
def load_rag_chain():
    """Chroma ë²¡í„°DB + Upstage LLMì„ ì´ìš©í•œ RAG ì²´ì¸ ë¡œë“œ"""

    # 1) ì„ë² ë”© + ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
    embeddings = UpstageEmbeddings(model="solar-embedding-1-large")

    # chroma_db í´ë”ëŠ” GitHub ì €ì¥ì†Œì— ê°™ì´ ì˜¬ë¼ì™€ ìˆì–´ì•¼ í•¨
    vectorstore = Chroma(
        embedding_function=embeddings,
        persist_directory="chroma_db"
    )

    retriever = vectorstore.as_retriever(search_kwargs={"k": 4})

    # 2) í”„ë¡¬í”„íŠ¸: í•™êµë„ì„œê´€ ë…ì„œì§€ì› ì‚¬ì„œ ì—­í• 
    prompt = ChatPromptTemplate.from_template(
        """
# RAGìš© í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
prompt = ChatPromptTemplate.from_template(
    """
ë„ˆëŠ” í•™êµë„ì„œê´€ì—ì„œ í•™ìƒë“¤ì˜ ë…ì„œí™œë™ì„ ë„ì™€ì£¼ëŠ” ë„ìš°ë¯¸ì•¼.
ì•„ë˜ 'ì°¸ê³  ë¬¸ì„œ(context)' ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, í•™ìƒì˜ ì§ˆë¬¸ì— ëŒ€í•´
ì¹œì ˆí•˜ê³  êµ¬ì²´ì ì¸ ë‹µë³€ì„ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì¤˜.

ê°€ëŠ¥í•˜ë©´:
- ë„ì„œê´€ ì´ìš© ê·œì •, ëŒ€ì¶œ/ë°˜ë‚©/ì—°ì¥ ë°©ë²•
- ì±… ê³ ë¥´ëŠ” ë°©ë²•, ë…í›„ê° ì‘ì„±ë²•, ë…ì„œ í† ë¡  ë°©ë²•
ë“±ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•´ ì¤˜.

ë§Œì•½ ë¬¸ì„œì— ì •ë³´ê°€ ì—†ìœ¼ë©´ ëª¨ë¥´ëŠ” ë¶€ë¶„ì€ ì†”ì§í•˜ê²Œ ëª¨ë¥¸ë‹¤ê³  ë§í•´.

[ì°¸ê³  ë¬¸ì„œ]
{context}

[ì§ˆë¬¸]
{question}
"""
)

# Upstage LLM (ê¸°ë³¸ Solar ì±— ëª¨ë¸)
llm = ChatUpstage()

# RAG ì²´ì¸ êµ¬ì„±
rag_chain = (
    {
        "context": retriever,          # ì§ˆë¬¸ì„ retrieverì— ë„£ìœ¼ë©´ ê´€ë ¨ ë¬¸ì„œ ë°˜í™˜
        "question": RunnablePassthrough()
    }
    | prompt
    | llm
    | StrOutputParser()
)


[ì°¸ê³  ë¬¸ì„œ]
{context}

[í•™ìƒì˜ ì§ˆë¬¸]
{question}
        """
    )

    llm = ChatUpstage()

    rag_chain = (
        {
            "context": retriever,
            "question": RunnablePassthrough()
        }
        | prompt
        | llm
        | StrOutputParser()
    )

    return rag_chain


# ì‹¤ì œ RAG ì²´ì¸ ì¤€ë¹„
rag_chain = load_rag_chain()


# -------------------------
# Streamlit ì±—ë´‡ UI ë¶€ë¶„
# -------------------------
st.set_page_config(page_title="í•™êµë„ì„œê´€ ë…ì„œí™œë™ ì§€ì› RAG ì±—ë´‡", page_icon="ğŸ“š")

st.title("ğŸ“š í•™êµë„ì„œê´€ ë…ì„œí™œë™ ì§€ì› RAG ì±—ë´‡")
st.caption("ë„ì„œê´€ ì†Œì¥ìë£Œì™€ ë…ì„œêµìœ¡ ìë£Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë…ì„œ ê´€ë ¨ ì§ˆë¬¸ì— ë‹µí•´ì£¼ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.")

with st.sidebar:
    st.subheader("â„¹ï¸ ì‚¬ìš© ì•ˆë‚´")
    st.markdown(
        """
**ì˜ˆì‹œ ì§ˆë¬¸**

- ë…ì„œëª¨ì„ ì§„í–‰ ë°©ë²•ì— ëŒ€í•´ ì•Œë ¤ì¤˜.
- ë…í›„ê° ì‘ì„± íŒ ìˆì„ê¹Œ?
- ë…ì„œí† ë¡  ê¸°ë²•ì˜ ì¢…ë¥˜ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜.

ë‹µë³€ì€ ë¯¸ë¦¬ ì¸ë±ì‹±í•´ ë‘” ë„ì„œê´€ ìë£Œì™€ ë…ì„œêµìœ¡ ìë£Œë¥¼ ìš°ì„ ì ìœ¼ë¡œ í™œìš©í•´ì„œ ìƒì„±ë©ë‹ˆë‹¤.
        """
    )

# ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™” ë³´ì—¬ì£¼ê¸°
for msg in st.session_state["messages"]:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ì‚¬ìš©ì ì…ë ¥
user_input = st.chat_input("ë…ì„œë°©ë²•, ë…ì„œí™œë™, ë„ì„œê´€ ì´ìš© ë“±ì— ëŒ€í•´ ê¶ê¸ˆí•œ ê²ƒì„ ë¬¼ì–´ë³´ì„¸ìš”.")

if user_input:
    # ì‚¬ìš©ì ë©”ì‹œì§€ í™”ë©´ì— ì¶”ê°€
    st.session_state["messages"].append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # RAG í˜¸ì¶œ
    with st.chat_message("assistant"):
        with st.spinner("ìƒê° ì¤‘ì…ë‹ˆë‹¤..."):
            answer = rag_chain.invoke(user_input)
            st.markdown(answer)

    # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µë„ íˆìŠ¤í† ë¦¬ì— ì €ì¥
    st.session_state["messages"].append({"role": "assistant", "content": answer})
